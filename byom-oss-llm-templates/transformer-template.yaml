apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: deepseek-coder-template
  annotations:
    scenarios.ai.sap.com/description: "Run a custom transformer server on SAP AI Core"
    scenarios.ai.sap.com/name: "deepseek-coder"
    executables.ai.sap.com/description: "Run a custom transformer server on SAP AI Core"
    executables.ai.sap.com/name: "deepseek-coder"
  labels:
    scenarios.ai.sap.com/id: "deepseek-coder"
    ai.sap.com/version: "2.1.1"
spec:
  inputs:
    parameters:
      - name: modelName # placeholder name
        default: "deepseek-coder" 
        type: string # required for every parameters
        description: "Model Name to be used in SAP Generative AI Hub SDK. Ensure an identical value as alias parameter"
      - name: resourcePlan
        type: string
        default: "infer.s" 
        description: "Resource Plan for free-tier"
  template:
    apiVersion: "serving.kserve.io/v1beta1"
    metadata:
      annotations: |
        autoscaling.knative.dev/metric: concurrency
        autoscaling.knative.dev/target: 1
        autoscaling.knative.dev/targetBurstCapacity: 0
      labels: |
        ai.sap.com/resourcePlan: "{{inputs.parameters.resourcePlan}}" 
    spec: |
      predictor:
        minReplicas: 1
        maxReplicas: 1
        containers:
        - name: kserve-container
          image: index.docker.io/ravivarmaiai/deepseek-coder:1.0
          ports:
            - containerPort: 8080
              protocol: TCP
          command: ["/bin/sh", "-c"]
          args:
            - >
              set -e && echo "-------------Starting transformer Server--------------" 
              && uvicorn server:app --host 0.0.0.0 --port 8080
          env:
            - name: MODEL_NAME
              value: "{{inputs.parameters.modelName}}"
            - name: HF_HOME
              value: "/tmp/hf-cache"
              
